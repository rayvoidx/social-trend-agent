services:
  trend-agent:
    build:
      context: ../..
      dockerfile: Dockerfile
    image: consumer-trend-agent:latest
    container_name: trend-agent
    command: ["uvicorn", "src.api.routes.dashboard:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - ../../artifacts:/app/artifacts
      - ../../logs:/app/logs
    ports:
      - ${API_PORT:-8000}:8000
    environment:
      # Required: LLM Configuration (Cloud-Neutral)
      - LLM_PROVIDER=${LLM_PROVIDER:-azure_openai}

      # OpenAI
      - OPENAI_API_TYPE=${OPENAI_API_TYPE:-azure}
      - OPENAI_API_BASE=${OPENAI_API_BASE:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_API_VERSION=${OPENAI_API_VERSION:-2024-02-15-preview}
      - OPENAI_DEPLOYMENT_NAME=${OPENAI_DEPLOYMENT_NAME:-gpt-5.1}
      - OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME:-gpt5.1}

      # Optional: Anthropic
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL_NAME=${ANTHROPIC_MODEL_NAME:-claude-3-5-sonnet-20241022}

      # Optional: Google Gemini
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - GEMINI_MODEL_NAME=${GEMINI_MODEL_NAME:-gemini-1.5-pro}
      - GEMINI_EMBEDDING_MODEL_NAME=${GEMINI_EMBEDDING_MODEL_NAME:-models/embedding-001}

      # Optional: Voyage AI (for embeddings)
      - VOYAGE_API_KEY=${VOYAGE_API_KEY:-}

      # Optional: Pinecone (Vector DB)
      - PINECONE_API_KEY=${PINECONE_API_KEY:-}

      # Optional: OpenAI Embedding
      - OPENAI_EMBEDDING_MODEL=${OPENAI_EMBEDDING_MODEL:-text-embedding-3-large}

      # Optional: Ollama
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://localhost:11434}
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME:-llama3.1}

      # Optional: News APIs
      - NEWS_API_KEY=${NEWS_API_KEY:-}
      - NAVER_CLIENT_ID=${NAVER_CLIENT_ID:-}
      - NAVER_CLIENT_SECRET=${NAVER_CLIENT_SECRET:-}

      # Optional: Video APIs
      - YOUTUBE_API_KEY=${YOUTUBE_API_KEY:-}
      - TIKTOK_CONNECTOR_TOKEN=${TIKTOK_CONNECTOR_TOKEN:-}

      # Optional: Web Search
      - TAVILY_API_KEY=${TAVILY_API_KEY:-}

      # Optional: Notifications
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL:-}
      - N8N_WEBHOOK_URL=${N8N_WEBHOOK_URL:-}

    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

  node-api:
    image: node:22
    container_name: trend-node-api
    working_dir: /app
    volumes:
      - ../../apps/node:/app
    command: ["sh", "-c", "npm install && npm run dev"]
    ports:
      - ${NODE_API_PORT:-3001}:3001
    environment:
      - PYTHON_API_BASE_URL=http://trend-agent:8000
    depends_on:
      - trend-agent

  frontend:
    image: node:22
    container_name: trend-frontend
    working_dir: /app
    volumes:
      - ../../apps/web:/app
    command: ["sh", "-c", "npm install && npm run dev -- --host 0.0.0.0 --port 5173"]
    environment:
      - VITE_API_URL=http://trend-agent:8000
      - VITE_NODE_API_URL=http://trend-node-api:3001
    ports:
      - "5173:5173"
    depends_on:
      - trend-agent
      - node-api

# Optional: Add Ollama service if using local LLM
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   restart: unless-stopped

# volumes:
#   ollama-data:
