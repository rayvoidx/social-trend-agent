#!/usr/bin/env python3
"""
AI Trend Analysis Agent - Main Entry Point

OpenAI GPT-5.1ë¥¼ ê¸°ë³¸ LLMìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” íŠ¸ë Œë“œ ë¶„ì„ ì—ì´ì „íŠ¸
API í‚¤ë§Œ ì„¤ì •í•˜ë©´ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
"""
import os
import sys
import argparse
import logging
import subprocess
import webbrowser
from pathlib import Path
from typing import Optional, List
from dotenv import load_dotenv

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def validate_environment():
    """
    í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ ë° ìë™ ì„¤ì •
    
    Returns:
        bool: í™˜ê²½ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€
    """
    logger.info("ğŸ” Validating environment configuration...")
    
    # Load .env file
    env_file = project_root / ".env"
    if not env_file.exists():
        logger.warning("âš ï¸  .env file not found. Creating from .env.example...")
        env_example = project_root / ".env.example"
        if env_example.exists():
            import shutil
            shutil.copy(env_example, env_file)
            logger.info("âœ… .env file created. Please edit it and add your API keys.")
            logger.info(f"ğŸ“ Edit: {env_file}")
            return False
        else:
            logger.error("âŒ .env.example not found. Cannot create .env file.")
            return False
    
    load_dotenv(env_file, override=True)
    
    # Check LLM configuration
    llm_provider = os.getenv("LLM_PROVIDER", "openai")
    logger.info(f"ğŸ¤– LLM Provider: {llm_provider}")
    
    if llm_provider == "openai":
        openai_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_key or openai_key.startswith("sk-your-"):
            logger.error("âŒ OPENAI_API_KEY is not set or is a placeholder.")
            logger.error("ğŸ“ Please edit .env file and add your OpenAI API key:")
            logger.error(f"   {env_file}")
            logger.error("   Get your key at: https://platform.openai.com/api-keys")
            return False
        
        model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-5.1")
        logger.info(f"âœ… OpenAI configured: {model_name}")
        logger.info(f"ğŸ”‘ API Key: {openai_key[:10]}...{openai_key[-4:]}")
        
    elif llm_provider == "azure_openai":
        azure_key = os.getenv("OPENAI_API_KEY", "")
        azure_base = os.getenv("OPENAI_API_BASE", "")
        if not azure_key or not azure_base:
            logger.error("âŒ Azure OpenAI configuration incomplete.")
            logger.error("   Required: OPENAI_API_KEY, OPENAI_API_BASE")
            return False
        logger.info(f"âœ… Azure OpenAI configured: {azure_base}")
        
    elif llm_provider == "anthropic":
        anthropic_key = os.getenv("ANTHROPIC_API_KEY", "")
        if not anthropic_key:
            logger.error("âŒ ANTHROPIC_API_KEY is not set.")
            return False
        logger.info("âœ… Anthropic Claude configured")
        
    elif llm_provider == "google":
        google_key = os.getenv("GOOGLE_API_KEY", "")
        if not google_key:
            logger.error("âŒ GOOGLE_API_KEY is not set.")
            return False
        logger.info("âœ… Google Gemini configured")
        
    elif llm_provider == "ollama":
        ollama_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        logger.info(f"âœ… Ollama configured: {ollama_url}")
        logger.info("â„¹ï¸  Note: Ollama does not require API key")
    
    else:
        logger.error(f"âŒ Unknown LLM_PROVIDER: {llm_provider}")
        logger.error("   Supported: openai, azure_openai, anthropic, google, ollama")
        return False
    
    # Check optional data source keys
    news_api_key = os.getenv("NEWS_API_KEY", "")
    naver_client_id = os.getenv("NAVER_CLIENT_ID", "")
    youtube_api_key = os.getenv("YOUTUBE_API_KEY", "")
    
    if not news_api_key and not naver_client_id:
        logger.warning("âš ï¸  No news API keys found. Using sample data.")
        logger.info("â„¹ï¸  To use real data, add NEWS_API_KEY or NAVER_CLIENT_ID to .env")
    else:
        logger.info("âœ… News API configured")
    
    if not youtube_api_key:
        logger.warning("âš ï¸  YOUTUBE_API_KEY not found. Viral video agent will use sample data.")
    else:
        logger.info("âœ… YouTube API configured")
    
    # Check MCP keys (optional)
    brave_api_key = os.getenv("BRAVE_API_KEY", "")
    database_url = os.getenv("DATABASE_URL", "")
    
    if brave_api_key:
        logger.info("âœ… Brave Search API configured (for MCP)")
    if database_url:
        logger.info("âœ… Database configured (for MCP)")
    
    logger.info("âœ… Environment validation completed")
    return True


def run_news_trend_agent(query: str, time_window: str = "7d", language: str = "ko", max_results: int = 20):
    """
    ë‰´ìŠ¤ íŠ¸ë Œë“œ ì—ì´ì „íŠ¸ ì‹¤í–‰
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        time_window: ì‹œê°„ ë²”ìœ„ (24h, 7d, 30d)
        language: ì–¸ì–´ (ko, en)
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
    """
    logger.info("ğŸš€ Starting News Trend Agent...")
    logger.info(f"   Query: {query}")
    logger.info(f"   Time Window: {time_window}")
    logger.info(f"   Language: {language}")
    
    # ì„¸ì…˜ ê´€ë¦¬ (CLI ëª¨ë“œ)
    from src.infrastructure.session_manager import SessionContext

    try:
        from src.agents.news_trend.graph import run_agent
        
        with SessionContext(mode="cli") as session:
            # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
            session.update_context("query", query)
            session.update_context("time_window", time_window)
            session.update_context("language", language)
            
            result = run_agent(
                query=query,
                time_window=time_window,
                language=language,
                max_results=max_results
            )
            
            logger.info("âœ… Analysis completed successfully")
            
            # Display results
            print("\n" + "="*80)
            print("ğŸ“Š ANALYSIS RESULTS")
            print("="*80)

            # Handle both dict and object result types
            if isinstance(result, dict):
                query = result.get('query', '')
                time_window = result.get('time_window', '')
                language = result.get('language', '')
                normalized = result.get('normalized', [])
                analysis = result.get('analysis', {})
                metrics = result.get('metrics', {})
            else:
                query = result.query
                time_window = result.time_window
                language = result.language
                normalized = result.normalized
                analysis = result.analysis or {}
                metrics = result.metrics or {}

            print(f"\nğŸ” Query: {query}")
            print(f"ğŸ“… Time Window: {time_window}")
            print(f"ğŸŒ Language: {language}")
            print(f"ğŸ“° Items Analyzed: {len(normalized)}")

            # Sentiment analysis
            sentiment = analysis.get('sentiment', {}) if isinstance(analysis, dict) else {}
            print("\nğŸ’­ Sentiment Analysis:")
            print(f"   Positive: {sentiment.get('positive', 0)} ({sentiment.get('positive_pct', 0):.1f}%)")
            print(f"   Neutral:  {sentiment.get('neutral', 0)} ({sentiment.get('neutral_pct', 0):.1f}%)")
            print(f"   Negative: {sentiment.get('negative', 0)} ({sentiment.get('negative_pct', 0):.1f}%)")

            # Keywords
            keywords_data = analysis.get('keywords', {}) if isinstance(analysis, dict) else {}
            keywords = keywords_data.get('top_keywords', []) if isinstance(keywords_data, dict) else []
            if keywords:
                print("\nğŸ”‘ Top Keywords:")
                for i, kw in enumerate(keywords[:5], 1):
                    print(f"   {i}. {kw['keyword']} ({kw['count']} times)")

            # Summary
            summary = analysis.get('summary', '') if isinstance(analysis, dict) else ''
            if summary:
                print("\nğŸ’¡ Summary:")
                print(f"   {summary[:200]}...")
            if metrics:
                print("\nğŸ“ˆ Quality Metrics:")
                print(f"   Coverage: {metrics.get('coverage', 0):.2f}")
                print(f"   Factuality: {metrics.get('factuality', 0):.2f}")
                print(f"   Actionability: {metrics.get('actionability', 0):.2f}")

            # Report file
            if isinstance(result, dict):
                run_id = result.get('run_id', '')
            else:
                run_id = result.run_id
            if run_id:
                report_file = project_root / "artifacts" / "news_trend_agent" / f"{run_id}.md"
                metrics_file = project_root / "artifacts" / "news_trend_agent" / f"{run_id}_metrics.json"
                print(f"\nğŸ“„ Full Report: {report_file}")
                print(f"ğŸ“Š Metrics JSON: {metrics_file}")
            
            print("\n" + "="*80)
            
            return result
        
    except Exception as e:
        logger.error(f"âŒ Error running news trend agent: {e}", exc_info=True)
        raise


def run_viral_video_agent(query: str, market: str = "KR", platforms: Optional[list] = None,
                          time_window: str = "24h", spike_threshold: float = 2.0):
    """
    ë°”ì´ëŸ´ ë¹„ë””ì˜¤ ì—ì´ì „íŠ¸ ì‹¤í–‰
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        market: ì‹œì¥ ì½”ë“œ (KR, US, JP)
        platforms: í”Œë«í¼ ë¦¬ìŠ¤íŠ¸ (youtube, tiktok, instagram)
        time_window: ì‹œê°„ ë²”ìœ„
        spike_threshold: ê¸‰ìƒìŠ¹ ì„ê³„ê°’
    """
    if platforms is None:
        platforms = ["youtube"]
    
    logger.info("ğŸš€ Starting Viral Video Agent...")
    logger.info(f"   Query: {query}")
    logger.info(f"   Market: {market}")
    logger.info(f"   Platforms: {platforms}")
    
    try:
        from src.agents.viral_video.graph import run_agent

        result = run_agent(
            query=query,
            market=market,
            platforms=platforms,
            time_window=time_window,
            spike_threshold=spike_threshold
        )
        
        logger.info("âœ… Analysis completed successfully")
        
        # Display results
        print("\n" + "="*80)
        print("ğŸ”¥ VIRAL VIDEO ANALYSIS RESULTS")
        print("="*80)

        print(f"\nğŸ” Query: {result.query}")
        print(f"ğŸŒ Market: {result.market}")
        print(f"ğŸ“± Platforms: {', '.join(result.platforms)}")
        print(f"ğŸ“… Time Window: {result.time_window}")

        # Viral statistics
        analysis = result.analysis or {}
        spikes = analysis.get('spikes', {}) if isinstance(analysis, dict) else {}
        print("\nğŸ”¥ Viral Statistics:")
        print(f"   Spikes Detected: {spikes.get('total_spikes', 0) if isinstance(spikes, dict) else 0}")
        print(f"   Total Items Analyzed: {analysis.get('total_items', 0) if isinstance(analysis, dict) else 0}")

        # Top videos
        normalized = result.normalized or []
        if normalized:
            print("\nğŸ† Top Videos:")
            for i, video in enumerate(normalized[:3], 1):
                print(f"   {i}. {video.get('title', 'N/A')}")
                print(f"      Views: {video.get('views', 0):,}")
                print(f"      Platform: {video.get('platform', 'N/A')}")
                print(f"      URL: {video.get('url', 'N/A')}")

        # Success factors
        success_factors = analysis.get('success_factors', []) if isinstance(analysis, dict) else []
        if success_factors:
            print("\nâœ¨ Success Factors:")
            for i, factor in enumerate(success_factors[:3], 1):
                print(f"   {i}. {factor}")

        # Report file
        run_id = result.run_id
        if run_id:
            report_file = project_root / "artifacts" / "viral_video_agent" / f"{run_id}.md"
            metrics_file = project_root / "artifacts" / "viral_video_agent" / f"{run_id}_metrics.json"
            print(f"\nğŸ“„ Full Report: {report_file}")
            print(f"ğŸ“Š Metrics JSON: {metrics_file}")
        
        print("\n" + "="*80)
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Error running viral video agent: {e}", exc_info=True)
        raise


def run_social_trend_agent(query: str, sources: Optional[list] = None,
                           rss_feeds: Optional[list] = None, time_window: str = "7d",
                           language: str = "ko", max_results: int = 50):
    """
    ì†Œì…œ íŠ¸ë Œë“œ ì—ì´ì „íŠ¸ ì‹¤í–‰

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        sources: ë°ì´í„° ì†ŒìŠ¤ ë¦¬ìŠ¤íŠ¸ (x, instagram, naver_blog, rss)
        rss_feeds: RSS í”¼ë“œ URL ë¦¬ìŠ¤íŠ¸
        time_window: ì‹œê°„ ë²”ìœ„
        language: ì–¸ì–´ (ko, en)
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
    """
    if sources is None:
        sources = ["x", "instagram", "naver_blog", "rss"]

    logger.info("ğŸš€ Starting Social Trend Agent...")
    logger.info(f"   Query: {query}")
    logger.info(f"   Sources: {sources}")
    logger.info(f"   Time Window: {time_window}")

    try:
        from src.agents.social_trend.graph import run_agent

        result = run_agent(
            query=query,
            sources=sources,
            rss_feeds=rss_feeds,
            time_window=time_window,
            language=language,
            max_results=max_results
        )

        logger.info("âœ… Analysis completed successfully")

        # Display results
        print("\n" + "="*80)
        print("ğŸ“± SOCIAL TREND ANALYSIS RESULTS")
        print("="*80)

        print(f"\nğŸ” Query: {result['query']}")
        print(f"ğŸ“… Time Window: {result['time_window']}")
        print(f"ğŸŒ Language: {result['language']}")
        print(f"ğŸ“Š Items Analyzed: {len(result['normalized'])}")

        # Sentiment analysis
        analysis = result.get('analysis', {})
        sentiment = analysis.get('sentiment', {})
        print("\nğŸ’­ Sentiment Analysis:")
        print(f"   Positive: {sentiment.get('positive', 0)} ({sentiment.get('positive_pct', 0):.1f}%)")
        print(f"   Neutral:  {sentiment.get('neutral', 0)} ({sentiment.get('neutral_pct', 0):.1f}%)")
        print(f"   Negative: {sentiment.get('negative', 0)} ({sentiment.get('negative_pct', 0):.1f}%)")

        # Keywords
        keywords_data = analysis.get('keywords', {})
        keywords = keywords_data.get('top_keywords', [])
        if keywords:
            print("\nğŸ”‘ Top Keywords:")
            for i, kw in enumerate(keywords[:5], 1):
                print(f"   {i}. {kw['keyword']} ({kw['count']} times)")

        # Summary
        summary = analysis.get('summary', '')
        if summary:
            print("\nğŸ’¡ Summary:")
            print(f"   {summary}")

        # Metrics
        metrics = result.get('metrics', {})
        if metrics:
            print("\nğŸ“ˆ Quality Metrics:")
            print(f"   Coverage: {metrics.get('coverage', 0):.2f}")
            print(f"   Factuality: {metrics.get('factuality', 0):.2f}")
            print(f"   Actionability: {metrics.get('actionability', 0):.2f}")

        # Report file
        run_id = result.get('run_id')
        if run_id:
            report_file = project_root / "artifacts" / "social_trend_agent" / f"{run_id}.md"
            print(f"\nğŸ“„ Full Report: {report_file}")

        print("\n" + "="*80)

        return result

    except Exception as e:
        logger.error(f"âŒ Error running social trend agent: {e}", exc_info=True)
        raise


def run_web_stack() -> None:
    """
    ëŒ€ì‹œë³´ë“œ ì›¹ ìŠ¤íƒ ì‹¤í–‰ (ë°±ì—”ë“œ + Node API + í”„ë¡ íŠ¸ì—”ë“œ).

    - FastAPI ëŒ€ì‹œë³´ë“œ (8000)
    - Node TypeScript ì¶”ì²œ API (3001)
    - React/Vite í”„ë¡ íŠ¸ì—”ë“œ (5173)
    """
    logger.info("ğŸš€ Starting web dashboard stack (Python API + Node API + Frontend)...")

    processes: List[subprocess.Popen] = []

    try:
        # 1) Python FastAPI ëŒ€ì‹œë³´ë“œ
        api_cmd = [
            sys.executable,
            "-m",
            "uvicorn",
            "src.api.routes.dashboard:app",
            "--host",
            "0.0.0.0",
            "--port",
            "8000",
        ]
        processes.append(
            subprocess.Popen(api_cmd, cwd=str(project_root))
        )
        logger.info("âœ… Started Python API on http://localhost:8000")

        # 2) Node TypeScript API
        node_api_dir = project_root / "apps" / "node"
        if node_api_dir.exists():
            node_cmd = ["sh", "-c", "npm install && npm run dev"]
            processes.append(
                subprocess.Popen(node_cmd, cwd=str(node_api_dir))
            )
            logger.info("âœ… Started Node API on http://localhost:3001")
        else:
            logger.warning("âš ï¸ apps/node directory not found, skipping Node API startup")

        # 3) Frontend (Vite)
        frontend_dir = project_root / "apps" / "web"
        if frontend_dir.exists():
            fe_cmd = [
                "sh",
                "-c",
                "npm install && npm run dev -- --host 0.0.0.0 --port 5173",
            ]
            processes.append(
                subprocess.Popen(fe_cmd, cwd=str(frontend_dir))
            )
            logger.info("âœ… Started frontend on http://localhost:5173")
        else:
            logger.warning("âš ï¸ apps/web directory not found, skipping frontend startup")

        # ë¸Œë¼ìš°ì € ìë™ ì˜¤í”ˆ
        try:
            webbrowser.open("http://localhost:5173")
            logger.info("ğŸŒ Opened browser at http://localhost:5173")
        except Exception:
            logger.warning("âš ï¸ Failed to open browser automatically. Please open http://localhost:5173 manually.")

        # ë©”ì¸ í”„ë¡œì„¸ìŠ¤ê°€ ì‚´ì•„ìˆë„ë¡ ì²« ë²ˆì§¸ í”„ë¡œì„¸ìŠ¤ë¥¼ ëŒ€ê¸°
        if processes:
            processes[0].wait()
        else:
            logger.error("âŒ No processes started. Check project structure and dependencies.")

    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Stopping web stack (Ctrl+C received)")
    finally:
        for p in processes:
            try:
                p.terminate()
            except Exception:
                pass


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        description="AI Trend Analysis Agent - OpenAI GPT-5.1 powered trend analysis",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # ëŒ€ì‹œë³´ë“œ ì›¹ ì•± ì‹¤í–‰ (ì¶”ì²œ UI í¬í•¨)
  python main.py --mode web

  # News trend analysis (CLI)
  python main.py --mode cli --agent news_trend_agent --query "AI" --window 7d

  # Viral video analysis (CLI)
  python main.py --mode cli --agent viral_video_agent --query "K-pop" --market KR

  # Social trend analysis (CLI)
  python main.py --mode cli --agent social_trend_agent --query "AI" --sources x instagram naver_blog

  # With custom parameters (CLI)
  python main.py --mode cli --agent news_trend_agent --query "ì „ê¸°ì°¨" --window 30d --language ko --max-results 50

Environment:
  Set OPENAI_API_KEY in .env file before running.
  Get your key at: https://platform.openai.com/api-keys
        """
    )

    parser.add_argument(
        "--mode",
        type=str,
        default="cli",
        choices=["cli", "web"],
        help="Execution mode: 'cli' for single-run agents, 'web' for full dashboard stack",
    )

    parser.add_argument(
        "--agent",
        type=str,
        choices=["news_trend_agent", "viral_video_agent", "social_trend_agent"],
        help="Agent to run"
    )
    
    parser.add_argument(
        "--query",
        type=str,
        help="Search query"
    )
    
    # News trend agent options
    parser.add_argument(
        "--window",
        type=str,
        default="7d",
        choices=["24h", "7d", "30d"],
        help="Time window for news trend agent (default: 7d)"
    )
    
    parser.add_argument(
        "--language",
        type=str,
        default="ko",
        choices=["ko", "en"],
        help="Language for news trend agent (default: ko)"
    )
    
    parser.add_argument(
        "--max-results",
        type=int,
        default=20,
        help="Maximum results for news trend agent (default: 20)"
    )
    
    # Viral video agent options
    parser.add_argument(
        "--market",
        type=str,
        default="KR",
        choices=["KR", "US", "JP", "GB", "DE"],
        help="Market code for viral video agent (default: KR)"
    )
    
    parser.add_argument(
        "--platform",
        type=str,
        action="append",
        choices=["youtube", "tiktok", "instagram"],
        help="Platform for viral video agent (can specify multiple)"
    )
    
    parser.add_argument(
        "--spike-threshold",
        type=float,
        default=2.0,
        help="Spike detection threshold for viral video agent (default: 2.0)"
    )

    # Social trend agent options
    parser.add_argument(
        "--sources",
        type=str,
        nargs="+",
        choices=["x", "instagram", "naver_blog", "rss"],
        help="Data sources for social trend agent (can specify multiple)"
    )

    parser.add_argument(
        "--rss-feeds",
        type=str,
        nargs="+",
        help="RSS feed URLs for social trend agent (can specify multiple)"
    )

    parser.add_argument(
        "--skip-validation",
        action="store_true",
        help="Skip environment validation"
    )
    
    args = parser.parse_args()
    
    if args.mode == "web":
        # ì›¹ ëŒ€ì‹œë³´ë“œ ëª¨ë“œ
        if not args.skip_validation and not validate_environment():
            logger.error("âŒ Environment validation failed. Please fix the issues above.")
            sys.exit(1)
        run_web_stack()
        return

    # CLI ì—ì´ì „íŠ¸ ëª¨ë“œ
    if not args.agent or not args.query:
        parser.error("--mode cli requires --agent and --query")

    # Print banner
    print("\n" + "=" * 80)
    print("ğŸ¤– AI Trend Analysis Agent")
    print("   Powered by OpenAI GPT-5.1")
    print("=" * 80 + "\n")

    # Validate environment
    if not args.skip_validation:
        if not validate_environment():
            logger.error("âŒ Environment validation failed. Please fix the issues above.")
            sys.exit(1)

    # Run agent
    try:
        if args.agent == "news_trend_agent":
            run_news_trend_agent(
                query=args.query,
                time_window=args.window,
                language=args.language,
                max_results=args.max_results,
            )
        elif args.agent == "viral_video_agent":
            platforms = args.platform if args.platform else ["youtube"]
            run_viral_video_agent(
                query=args.query,
                market=args.market,
                platforms=platforms,
                time_window=args.window,
                spike_threshold=args.spike_threshold,
            )
        elif args.agent == "social_trend_agent":
            sources = args.sources if args.sources else ["x", "instagram", "naver_blog", "rss"]
            run_social_trend_agent(
                query=args.query,
                sources=sources,
                rss_feeds=args.rss_feeds,
                time_window=args.window,
                language=args.language,
                max_results=args.max_results,
            )

        logger.info("âœ… Agent execution completed successfully")
        sys.exit(0)

    except KeyboardInterrupt:
        logger.info("\nâš ï¸  Interrupted by user")
        sys.exit(130)
    except Exception as e:
        logger.error(f"âŒ Fatal error: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()

